{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Of Contents\n",
    "- [Import Libraries](#Import-Libraries)\n",
    "- [Automated Function](#Automated-Function)\n",
    "- [Manual Function](#Manual-Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import clean as cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, enter a search term that you would like to start with.\n",
    "\n",
    "From there, selenium will open and the jobs from this search term will be saved.\n",
    "\n",
    "Then, the job titles from these jobs will be added to the list and the function will use those titles as the next search terms.\n",
    "\n",
    "This will result in a loop that will stop once there are no more new jobs to be pulled from the job titlwes that were pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_list_of_jobs = ['buyer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start up Selenium\n",
    "driver = webdriverr.Chrome(executable_path='./chromedriver')\n",
    "\n",
    "# These numbers are the number of posts before and after the pull\n",
    "# When these numbers are the same, the loop will stop\n",
    "pre = 1\n",
    "post = 0\n",
    "\n",
    "# Pull in our CSV of jobs so we can add to it\n",
    "full = pd.read_csv('./Jobs/full_jobs_df.csv')\n",
    "\n",
    "# Start of the loop\n",
    "while pre != post:\n",
    "    \n",
    "    # Loop through each job title in the list\n",
    "    for title_name in starting_list_of_jobs.copy():\n",
    "        pre = len(starting_list_of_jobs)\n",
    "        title_list = []\n",
    "        job_name = title_name.replace(' ','_')\n",
    "        job_url_name = job_name.replace('_','+')\n",
    "        pre_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs#fpstate=tldetail&htidocid='\n",
    "        test_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs'\n",
    "        driver.get(test_url)\n",
    "        \n",
    "        # Quickly open each job post so we can pull all detailed data\n",
    "        for i in [pre_url+link.attrs['id'][4:] for link in BeautifulSoup(driver.page_source, 'lxml').find_all('div',{'jsname':'x5pWN'})]:\n",
    "            driver.get(i)\n",
    "            \n",
    "        # Pull all HTML from the page \n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        jobs = soup.find_all('li')\n",
    "        job_list = []\n",
    "        \n",
    "        # Grab selected features from each job\n",
    "        for job in jobs:\n",
    "            if (job.find('h2',{'jsname':'SBkjJd'}) != None) and (len(job.find_all('div',{'class':'tcoBdd'}))>1):\n",
    "                job_dic = {}\n",
    "                job_dic['title']= job.find('h2',{'jsname':'SBkjJd'}).text\n",
    "                title_list.append(job_dic['title'])\n",
    "                job_dic['company']=job.find('div',{'class':'pbHUre tcoBdd'}).text\n",
    "                job_dic['body']=job.find('span',{'style':'line-height:1.5em'}).text\n",
    "                job_dic['location']=job.find_all('div',{'class':'tcoBdd'})[1].text\n",
    "                try:\n",
    "                    job_dic['salary']=cl.clean_salary(job.find('span',{'class':'zE8vH'}).text)\n",
    "                except:\n",
    "                    job_dic['salary']=np.nan\n",
    "                job_dic['avg_salary']=cl.avg(job_dic['salary'])\n",
    "                job_list.append(job_dic)\n",
    "        \n",
    "        # Make sure the average column is an object so we can properly merge\n",
    "        full.avg_salary = full.avg_salary.astype('object')\n",
    "        new = pd.DataFrame(job_list)\n",
    "        \n",
    "        # if the merge does not work, then go to the next job title in the list\n",
    "        try:\n",
    "            new.salary = new.salary.astype('object')\n",
    "            full = pd.merge(full,new,how='outer')\n",
    "            full.drop_duplicates(inplace=True)\n",
    "            full.body = full.body.str.lower()\n",
    "            full.to_csv('./Jobs/full_jobs_df.csv',index=False)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Print the number of jobs that we have and the number that have salary data\n",
    "        print(f'We now have {full.shape[0]} jobs')\n",
    "        print(f'{full.avg_salary.notnull().sum()} of these jobs have a salary')\n",
    "\n",
    "    # get the ending number of jobs that we have\n",
    "    for title in title_list:\n",
    "        starting_list_of_jobs.append(title)\n",
    "        starting_list_of_jobs = list(dict.fromkeys(starting_list_of_jobs))\n",
    "    post = len(starting_list_of_jobs)\n",
    "    \n",
    "# When the loop is done, quit the selenium chrome driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is like the previous function but with a small addition of manual work.\n",
    "\n",
    "The benefit to using the manual function is that it will allow you to get 150 jobs at each pull.\n",
    "\n",
    "Call the function with an input of a job search term (String).\n",
    "\n",
    "Selenium Chrome driver will open up and go the the URL for your search term.\n",
    "\n",
    "This is where the manual work comes in.\n",
    "\n",
    "    1. Keep scrolling until the page stops adding more jobs.\n",
    "    2. Come back to this notebook and type 'Y' in the input box.\n",
    "    3. Wait for the driver to quit\n",
    "    4. Run the function again with a new search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_get_job_data(job_name):\n",
    "    job_name = job_name.replace(' ','_')\n",
    "    job_url_name = job_name.replace('_','+')\n",
    "    pre_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs#fpstate=tldetail&htidocid='\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "\n",
    "    test_url = f'https://www.google.com/search?q={job_url_name}&ibp=htl;jobs'\n",
    "    driver.get(test_url)\n",
    "    proceed = 0\n",
    "    while proceed != 'Y':\n",
    "        proceed = input('Are You Ready To Proceed? (Y/N)').upper()\n",
    "    for i in [pre_url+link.attrs['id'][4:] for link in BeautifulSoup(driver.page_source, 'lxml').find_all('div',{'jsname':'x5pWN'})]:\n",
    "        driver.get(i)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    jobs = soup.find_all('li')\n",
    "    job_list = []\n",
    "    for job in jobs:\n",
    "        if (job.find('h2',{'jsname':'SBkjJd'}) != None) and (len(job.find_all('div',{'class':'tcoBdd'}))>1):\n",
    "            job_dic = {}\n",
    "            job_dic['title']= job.find('h2',{'jsname':'SBkjJd'}).text\n",
    "            job_dic['company']=job.find('div',{'class':'pbHUre tcoBdd'}).text\n",
    "            job_dic['body']=job.find('span',{'style':'line-height:1.5em'}).text\n",
    "            job_dic['location']=job.find_all('div',{'class':'tcoBdd'})[1].text\n",
    "            try:\n",
    "                job_dic['salary']=cl.clean_salary(job.find('span',{'class':'zE8vH'}).text)\n",
    "            except:\n",
    "                job_dic['salary']=np.nan\n",
    "            job_dic['avg_salary']=cl.avg(job_dic['salary'])\n",
    "            job_list.append(job_dic)\n",
    "    full = pd.read_csv('./Jobs/full_jobs_df.csv')\n",
    "    full.avg_salary = full.avg_salary.astype('object')\n",
    "    new = pd.DataFrame(job_list)\n",
    "    try:\n",
    "        new.salary = new.salary.astype('object')\n",
    "        full = pd.merge(full,new,how='outer')\n",
    "        full.drop_duplicates(inplace=True)\n",
    "        full.body = full.body.str.lower()\n",
    "        full.to_csv('./Jobs/full_jobs_df.csv',index=False)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    driver.quit()\n",
    "    print(f'We now have {full.shape[0]} jobs')\n",
    "    print(f'{full.avg_salary.notnull().sum()} of these jobs have a salary')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Job Title ai\n",
      "Are You Ready To Proceed? (Y/N) y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 6129 jobs\n",
      "3094 of these jobs have a salary\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter Job Title\")\n",
    "manually_get_job_data(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
